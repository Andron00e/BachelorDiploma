\section{Сопутствующие работы}
\label{sec:relwork}

Подходы к классификации изображений с использованием концептуальных моделей - быстро развивающаяся область, поскольку в разделе \ref{sec:bottls} упоминаются преимущества их возможностей для интерпретации, то уже было представлено множество достаточных методов. В ранних работах \cite{koh2020concept,losch2019interpretability,Marcos_2020_ACCV} предлагается обучать CNN \cite{5537907} и создавать дополнительный слой перед последним полностью связанным слоем, где каждый нейрон соответствует интерпретируемому человеком понятию. Поскольку модели "узкого места" страдают от необходимости подготовки набора концепций, поиск эффективного метода создания набора поддерживаемых концепций является необходимой задачей. В предыдущих работах по безэтикетному, постхоковому CBM и LaBo \cite{oikarinen2023labelfree,yuksekgonul2023posthoc,yang2023language} прослеживается тенденция к созданию фреймворков (как преобразовать существующую модель в модель узкого места) вместо того, чтобы изучать модели с нуля. Они также показывают методы создания набора достаточных концептов и вводят новые метрики в классификацию с помощью CBM. Поскольку хорошо подготовленный набор концептов является ключевым ингредиентом проблемы CBM, \cite{schwalbe2022concept} предлагает общий обзор методов, использующих вкрапления концептов.Помимо прочего, авторы \cite{oikarinen2023labelfree} обучают модель по двум алгоритмам: голова классификатора с решателем GLM-SAGA \cite{pmlr-v139-wong21b} и узкие слои с вариантами косинусного сходства, что близко к нашему конвейеру. \cite{menon2022visual} сообщают о методе, который не требует обучения базовой модели, вместо этого они запрашивают у CLIP определенный паттерн и находят конечный класс с помощью предложенной формулы, а \cite{oikarinen2023clipdissect} предлагает способ описания нейронов скрытых слоев CLIP. \cite{gao2022pyramidclip} предлагает построить входную пирамиду с различными семантическими уровнями для каждой модальности и объединить визуальные и лингвистические элементы в иерархию, что удобно для обнаружения объектов. \cite{pmlr-v139-wong21b} предлагает идею сохранить конечный слой FC разреженным, что делает его более интерпретируемым. \cite{kazmierczak2023clipqda} вмешивается в латентное пространство CLIP и показывает, что оно может быть эффективно смоделировано как смесь гауссианов. Также отметим, что в недавней работе \cite{Alukaev_2023} предлагается использовать сигмоид Гумбеля после экстракторов признаков (для концептов и изображений), которые дают разреженное представление концептов. Идея разреженности также находит свое продолжение в работе \cite{panousis2023discover}, где авторы представляют новый тип слоев Local Winner-Takes-All \cite{panousis2019nonparametric}, основанных на активационной разреженности. Предыдущие работы по разреженности также схожи с нашей, но мы, в свою очередь, создаем варианты контрастных потерь для обучения CBM.

\vspace{-0.3cm}
\section{Предварительная информация}\label{sec:prel}
\vspace{-0.2cm}

В этом разделе мы приводим все обозначения, необходимые для представления наших методов обучения моделей Concept Bottleneck.

\paragraph{Нотация.}\label{sec:notation} В основном мы работаем с OpenAI CLIP, он состоит из двух кодировщиков, один для изображений, другой для текста. Эти кодировщики позволяют нам получить векторное представление для обоих типов данных в многомерном пространстве одной и той же размерности (обычно 512). Поэтому мы используем следующие обозначения. Мы называем $f_{\mathrm{T}}(t, \theta)$ выходом текстового кодера $f_{\mathrm{T}}$, то есть вкраплениями текста из партии текстовых примеров $t$. Под $\theta$ мы понимаем параметры текстового кодера, если он не поддается обучению, то мы опускаем эти параметры. Также, поскольку в большинстве экспериментов мы настраиваем лишь небольшое количество весов исходной модели CLIP (см. \cref{tab:backbone_nets}), а полностью обучаем только новые встроенные слои, для простоты мы указываем веса $\theta$ с одинаковым символом для обоих кодеров. Получив мини-пакет изображений $x$, мы используем $f_{\mathrm{I}}(x, \theta)$ для кодировщика изображений $f_{\mathrm{I}}$ на выходе, т.е. вкраплений входных изображений, каждое размерностью 512 для основных конфигураций модели CLIP. $\langle , \rangle$ обозначает скалярное (точечное) произведение, через $\times$ мы обозначаем декартово произведение двух множеств. Для векторов $\|z\|$ - это норма на векторном пространстве, которому принадлежит $z$. Как правило, под этим обозначением подразумевается $2$-норма для векторов из $\mathbb{R}^{n}$ или норма Фробениуса для матриц из $\mathbb{R}^{m\times n}$, если не указано иное.